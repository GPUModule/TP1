{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUDA-GPU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJMIqMIupjl9"
      },
      "outputs": [],
      "source": [
        "!nvcc -V"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "!apt-get remove cuda-*\n",
        "!apt autoremove\n",
        "!apt-get update"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_0WZ72H9WKYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda-9.2"
      ],
      "metadata": {
        "id": "gAeionhAWlPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "id": "lAuTDb_SpyIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "id": "mlg1rb6tqPMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "    int\n",
        "    main()\n",
        "{\n",
        "    std::cout << \"CUDA sur Google Colab fonctionne\\n\";\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "J1PvJx8KqVKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cstdio>\n",
        "#include <iostream>\n",
        " \n",
        "using namespace std;\n",
        " \n",
        "__global__ void maxi(int* a, int* b, int n)\n",
        "{\n",
        "    int block = 256 * blockIdx.x;\n",
        "    int max = 0;\n",
        " \n",
        "    for (int i = block; i < min(256 + block, n); i++) {\n",
        " \n",
        "        if (max < a[i]) {\n",
        "            max = a[i];\n",
        "        }\n",
        "    }\n",
        "    b[blockIdx.x] = max;\n",
        "}\n",
        " \n",
        "int main()\n",
        "{\n",
        " \n",
        "    int n;\n",
        "    n = 3 >> 2;\n",
        "    int a[n];\n",
        " \n",
        "    for (int i = 0; i < n; i++) {\n",
        "        a[i] = rand() % n;\n",
        "        cout << a[i] << \"\\t\";\n",
        "    }\n",
        " \n",
        "    cudaEvent_t start, end;\n",
        "    int *ad, *bd;\n",
        "    int size = n * sizeof(int);\n",
        "    cudaMalloc(&ad, size);\n",
        "    cudaMemcpy(ad, a, size, cudaMemcpyHostToDevice);\n",
        "    int grids = ceil(n * 1.0f / 256.0f);\n",
        "    cudaMalloc(&bd, grids * sizeof(int));\n",
        " \n",
        "    dim3 grid(grids, 1);\n",
        "    dim3 block(1, 1);\n",
        " \n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&end);\n",
        "    cudaEventRecord(start);\n",
        " \n",
        "    while (n > 1) {\n",
        "        maxi<<<grids, block>>>(ad, bd, n);\n",
        "        n = ceil(n * 1.0f / 256.0f);\n",
        "        cudaMemcpy(ad, bd, n * sizeof(int), cudaMemcpyDeviceToDevice);\n",
        "    }\n",
        " \n",
        "    cudaEventRecord(end);\n",
        "    cudaEventSynchronize(end);\n",
        " \n",
        "    float time = 0;\n",
        "    cudaEventElapsedTime(&time, start, end);\n",
        " \n",
        "    int ans[2];\n",
        "    cudaMemcpy(ans, ad, 4, cudaMemcpyDeviceToHost);\n",
        " \n",
        "    cout << \"The maximum element is : \" << ans[0] << endl;\n",
        " \n",
        "    cout << \"The time required : \";\n",
        "    cout << time << endl;\n",
        "}"
      ],
      "metadata": {
        "id": "Jwl-4BEerRo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <math.h>\n",
        "\n",
        "#define N 8192\n",
        "#define THREADS_PER_BLOCK 256\n",
        "#define SQRT_THREADS_PER_BLOCK sqrt(THREADS_PER_BLOCK)\n",
        "\n",
        "struct event_pair\n",
        "{\n",
        "  cudaEvent_t start;\n",
        "  cudaEvent_t end;\n",
        "};\n",
        "\n",
        "inline void start_timer(event_pair * p)\n",
        "{\n",
        "  cudaEventCreate(&p->start);\n",
        "  cudaEventCreate(&p->end);\n",
        "  cudaEventRecord(p->start, 0);\n",
        "}\n",
        "\n",
        "\n",
        "inline void stop_timer(event_pair * p, char * kernel_name)\n",
        "{\n",
        "  cudaEventRecord(p->end, 0);\n",
        "  cudaEventSynchronize(p->end);\n",
        "  \n",
        "  float elapsed_time;\n",
        "  cudaEventElapsedTime(&elapsed_time, p->start, p->end);\n",
        "  printf(\"%s took %.4f ms\\n\",kernel_name, elapsed_time);\n",
        "  cudaEventDestroy(p->start);\n",
        "  cudaEventDestroy(p->end);\n",
        "}\n",
        "\n",
        "void checkCUDAError(const char*);\n",
        "void random_floats(float *a, int n);\n",
        "void print_array(float *a, int n, char *name);\n",
        "int validate(float *a, float *ref, int n);\n",
        "\n",
        "__global__ void simple_convolution1D_kernel(float* c, float* a, float* filter, int f, int n) {\n",
        "  // A completer\n",
        "}\n",
        "\n",
        "__global__ void shared_convolution1D_kernel(float* c, float* a, float* filter, int f, int n) {\n",
        "  // A completer\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "\tsrand( time( NULL ) );\n",
        "\n",
        "\tfloat *a, *filter, *c;\n",
        "\tfloat *d_a, *d_filter, *d_c;\n",
        "\tint errors;\n",
        "\t\n",
        "\t//int f =\n",
        "\t//int n_c = \n",
        "\tunsigned int filter_size = f * sizeof(float);\n",
        "\tunsigned int size = N * sizeof(float);\n",
        "\tunsigned int c_size = n_c * sizeof(float);\n",
        "\n",
        "\tevent_pair timer;\n",
        "\t// Alloc space for device copies\n",
        "\t// A completer\n",
        "\t//cudaMalloc\n",
        "\t//cudaMalloc\n",
        "\t//cudaMalloc\n",
        "\tcheckCUDAError(\"CUDA malloc\");\n",
        "\n",
        "\t// Alloc space for host copies of a, b, c and setup input values\n",
        "\t// A completer\n",
        "\t//a = (float*)malloc(size);\n",
        "\t//filter = (float*)malloc(filter_size);\n",
        "\t//c = (float*)malloc(c_size);\n",
        "\n",
        "\trandom_floats(a, N);\n",
        "\trandom_floats(filter, f);\n",
        "\tprint_array(a, N, \"a\");\n",
        "\tprint_array(filter, f, \"filter\");\n",
        "\n",
        "\t// Copy inputs to device\n",
        "\t// A completer\n",
        "\t//cudaMemcpy\n",
        "\t//cudaMemcpy\n",
        "\tcheckCUDAError(\"CUDA memcpy Host to Device\");\n",
        "\n",
        "\t// Launch add() kernel on GPU\n",
        "\tdim3 blocksPerGrid((N + THREADS_PER_BLOCK -1)/THREADS_PER_BLOCK);\n",
        "\tdim3 threadsPerBlock(THREADS_PER_BLOCK);\n",
        "\tstart_timer(&timer);\n",
        "\tsimple_convolution1D_kernel<<<blocksPerGrid, threadsPerBlock>>>(d_c, d_a, d_filter, f, N);\n",
        "\tcheckCUDAError(\"CUDA kernel\");\n",
        "\tstop_timer(&timer,\"Convolution 1D sur GPU\");\n",
        "\t\n",
        "\t// Copy result back to host\n",
        "\t// A completer\n",
        "\t// cudaMemcpy\n",
        "\tcheckCUDAError(\"CUDA memcpy Device to Host\");\n",
        "\n",
        "\tprint_array(c, n_c, \"c\");\n",
        "\t\n",
        "\t//start_timer(&timer);\n",
        "\t//shared_convolution1D_kernel<<<blocksPerGrid, threadsPerBlock>>>(d_cs, d_a, d_filter, f, N);\n",
        "\t//checkCUDAError(\"CUDA kernel\");\n",
        "\t//stop_timer(&timer,\"Convolution 1D shared sur GPU\");\n",
        "\n",
        "\n",
        "\t// validate\n",
        "\t//errors = validate(c, cs, n_c);\n",
        "\t//printf(\"CUDA GPU result has %d errors.\\n\", errors);\n",
        "\n",
        "\t// Cleanup\n",
        "\tfree(a); free(filter); free(c);\n",
        "\tcudaFree(d_a); cudaFree(d_filter); cudaFree(d_c);\n",
        "\tcheckCUDAError(\"CUDA cleanup\");\n",
        "\n",
        "\treturn 0;\n",
        "}\n",
        "\n",
        "void checkCUDAError(const char *msg)\n",
        "{\n",
        "\tcudaError_t err = cudaGetLastError();\n",
        "\tif (cudaSuccess != err)\n",
        "\t{\n",
        "\t\tfprintf(stderr, \"CUDA ERROR: %s: %s.\\n\", msg, cudaGetErrorString(err));\n",
        "\t\texit(EXIT_FAILURE);\n",
        "\t}\n",
        "}\n",
        "\n",
        "void random_floats(float *a, int n)\n",
        "{\n",
        "\tfor (unsigned int i = 0; i < n; i++){\n",
        "\t\t\ta[i] = (float)(rand() % 101);\n",
        "\t}\n",
        "}\n",
        "\n",
        "void print_array(float *a, int n, char*name){\n",
        "\n",
        "\tprintf(\"%s : [ \",name);\n",
        "\tfor (unsigned int i = 0; i < n; i++){\n",
        "\t\t\tprintf(\"%.4f \",a[i]);\n",
        "\t}\n",
        "\tprintf(\"]\\n\");\n",
        "}\n",
        "\n",
        "int validate(float *a, float *ref, int n){\n",
        "\tint errors = 0;\n",
        "\tfor (unsigned int i = 0; i < n; i++){\n",
        "\t\tif (a[i] != ref[i]){\n",
        "\t\t\terrors++;\n",
        "\t\t\tfprintf(stderr, \"ERROR at index %d: GPU result %f does not match CPU value of %f\\n\", i, a[i], ref[i]);\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\treturn errors;\n",
        "}"
      ],
      "metadata": {
        "id": "FbaG8P7hrtJh",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <math.h>\n",
        "\n",
        "#define N 2048\n",
        "#define THREADS_PER_BLOCK_X 16\n",
        "#define THREADS_PER_BLOCK_Y 16\n",
        "\n",
        "struct event_pair\n",
        "{\n",
        "  cudaEvent_t start;\n",
        "  cudaEvent_t end;\n",
        "};\n",
        "\n",
        "inline void start_timer(event_pair * p)\n",
        "{\n",
        "  cudaEventCreate(&p->start);\n",
        "  cudaEventCreate(&p->end);\n",
        "  cudaEventRecord(p->start, 0);\n",
        "}\n",
        "\n",
        "\n",
        "inline void stop_timer(event_pair * p, char * kernel_name)\n",
        "{\n",
        "  cudaEventRecord(p->end, 0);\n",
        "  cudaEventSynchronize(p->end);\n",
        "  \n",
        "  float elapsed_time;\n",
        "  cudaEventElapsedTime(&elapsed_time, p->start, p->end);\n",
        "  printf(\"%s took %.4f ms\\n\",kernel_name, elapsed_time);\n",
        "  cudaEventDestroy(p->start);\n",
        "  cudaEventDestroy(p->end);\n",
        "}\n",
        "\n",
        "void checkCUDAError(const char*);\n",
        "void random_floats(float *a, int n);\n",
        "void print_array(float *a, int n, char *name);\n",
        "int validate(float *a, float *ref, int n);\n",
        "\n",
        "__global__ void simple_convolution2D_kernel(float* c, float* a, float* filter, int f, int n) {\n",
        "  // A completer\n",
        "}\n",
        "\n",
        "__global__ void shared_convolution2D_kernel(float* c, float* a, float* filter, int f, int n) {\n",
        "  // A completer\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "\tsrand( time( NULL ) );\n",
        "\n",
        "\tfloat *a, *filter, *c;\n",
        "\tfloat *d_a, *d_filter, *d_c;\n",
        "\tint errors;\n",
        "\t\n",
        "\t//int f =\n",
        "\t//int n_c = \n",
        "\tunsigned int filter_size = f * sizeof(float);\n",
        "\tunsigned int size = N * sizeof(float);\n",
        "\tunsigned int c_size = n_c * sizeof(float);\n",
        "\n",
        "\tevent_pair timer;\n",
        "\t// Alloc space for device copies\n",
        "\t// A completer\n",
        "\t//cudaMalloc\n",
        "\t//cudaMalloc\n",
        "\t//cudaMalloc\n",
        "\tcheckCUDAError(\"CUDA malloc\");\n",
        "\n",
        "\t// Alloc space for host copies\n",
        "\t// A completer\n",
        "\t//a = (float*)malloc(size);\n",
        "\t//filter = (float*)malloc(filter_size);\n",
        "\t//c = (float*)malloc(c_size);\n",
        "\n",
        "\trandom_floats(a, N);\n",
        "\trandom_floats(filter, f);\n",
        "\tprint_array(a, N, \"a\");\n",
        "\tprint_array(filter, f, \"filter\");\n",
        "\n",
        "\t// Copy inputs to device\n",
        "\t// A completer\n",
        "\t//cudaMemcpy\n",
        "\t//cudaMemcpy\n",
        "\tcheckCUDAError(\"CUDA memcpy Host to Device\");\n",
        "\n",
        "\t// Launch kernel on GPU\n",
        "\tdim3 blocksPerGrid((N + THREADS_PER_BLOCK -1)/THREADS_PER_BLOCK);\n",
        "\tdim3 threadsPerBlock(THREADS_PER_BLOCK);\n",
        "\tstart_timer(&timer);\n",
        "\tsimple_convolution1D_kernel<<<blocksPerGrid, threadsPerBlock>>>(d_c, d_a, d_filter, f, N);\n",
        "\tcheckCUDAError(\"CUDA kernel\");\n",
        "\tstop_timer(&timer,\"Convolution 1D sur GPU\");\n",
        "\t\n",
        "\t// Copy result back to host\n",
        "\t// A completer\n",
        "\t// cudaMemcpy\n",
        "\tcheckCUDAError(\"CUDA memcpy Device to Host\");\n",
        "\n",
        "\tprint_array(c, n_c, \"c\");\n",
        "\t\n",
        "\t//start_timer(&timer);\n",
        "\t//shared_convolution2D_kernel<<<blocksPerGrid, threadsPerBlock>>>(d_cs, d_a, d_filter, f, N);\n",
        "\t//checkCUDAError(\"CUDA kernel\");\n",
        "\t//stop_timer(&timer,\"Convolution 1D shared sur GPU\");\n",
        "\n",
        "\n",
        "\t// validate\n",
        "\t//errors = validate(c, cs, n_c);\n",
        "\t//printf(\"CUDA GPU result has %d errors.\\n\", errors);\n",
        "\n",
        "\t// Cleanup\n",
        "\tfree(a); free(filter); free(c);\n",
        "\tcudaFree(d_a); cudaFree(d_filter); cudaFree(d_c);\n",
        "\tcheckCUDAError(\"CUDA cleanup\");\n",
        "\n",
        "\treturn 0;\n",
        "}\n",
        "\n",
        "void checkCUDAError(const char *msg)\n",
        "{\n",
        "\tcudaError_t err = cudaGetLastError();\n",
        "\tif (cudaSuccess != err)\n",
        "\t{\n",
        "\t\tfprintf(stderr, \"CUDA ERROR: %s: %s.\\n\", msg, cudaGetErrorString(err));\n",
        "\t\texit(EXIT_FAILURE);\n",
        "\t}\n",
        "}\n",
        "\n",
        "void random_floats(float *a, int n)\n",
        "{\n",
        "\tfor (unsigned int i = 0; i < n; i++){\n",
        "\t\t\ta[i] = (float)(rand() % 101);\n",
        "\t}\n",
        "}\n",
        "\n",
        "void print_array(float *a, int n, char*name){\n",
        "\n",
        "\tprintf(\"%s : [ \",name);\n",
        "\tfor (unsigned int i = 0; i < n; i++){\n",
        "\t\t\tprintf(\"%.4f \",a[i]);\n",
        "\t}\n",
        "\tprintf(\"]\\n\");\n",
        "}\n",
        "\n",
        "int validate(float *a, float *ref, int n){\n",
        "\tint errors = 0;\n",
        "\tfor (unsigned int i = 0; i < n; i++){\n",
        "\t\tif (a[i] != ref[i]){\n",
        "\t\t\terrors++;\n",
        "\t\t\tfprintf(stderr, \"ERROR at index %d: GPU result %f does not match CPU value of %f\\n\", i, a[i], ref[i]);\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\treturn errors;\n",
        "}"
      ],
      "metadata": {
        "id": "LPQOuQf3sf8D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}